import streamlit as st
import google.generativeai as genai

# --- CONFIGURACI√ìN DE LA IA ---
# Pega aqu√≠ tu API Key
genai.configure(api_key="TU_API_KEY_AQU√ç")

# Instrucciones del sistema (Tu prompt de tutor)
SYSTEM_PROMPT = """
Eres un Tutor Socr√°tico de C√°lculo Diferencial. 
REGLA DE ORO: NUNCA des la respuesta final. 
Si el alumno pregunta por una derivada o l√≠mite, responde con una pregunta gu√≠a.
Usa LaTeX para las f√≥rmulas. 
Si el alumno se frustra, s√© emp√°tico pero no resuelvas el ejercicio.
"""

model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    system_instruction=SYSTEM_PROMPT
)

# --- INTERFAZ DE LA WEB ---
st.title("üéì Tutor IA: C√°lculo Diferencial")
st.markdown("Bienvenido. Cu√©ntame en qu√© ejercicio est√°s trabajando y lo resolveremos juntos paso a paso.")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("¬øEn qu√© puedo ayudarte?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # Enviar historial al modelo
        chat = model.start_chat(history=[
            {"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages[:-1]
        ])
        response = chat.send_message(prompt)
        st.markdown(response.text)
        st.session_state.messages.append({"role": "assistant", "content": response.text})
